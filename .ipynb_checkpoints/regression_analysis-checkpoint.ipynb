{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ast, json\n",
    "import math\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.stats import weightstats as stests\n",
    "import scipy.stats as scs\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as stats\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as ctb\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful methods\n",
    "def get_elems_list(row, cols):\n",
    "    elem_comb = {}\n",
    "    elem_list = []\n",
    "    i = 0\n",
    "    for a in row:\n",
    "        if not math.isnan(a):\n",
    "            elem_list.append(cols[i])\n",
    "        i+=1\n",
    "    elem_comb['elements'] = elem_list\n",
    "    return elem_comb\n",
    "\n",
    "def get_data_rep(df):\n",
    "    elements = get_elements(df)\n",
    "    ecols = elements.columns\n",
    "    data = df.drop(columns = ecols)\n",
    "    e = pd.DataFrame()\n",
    "    for i in range (0, len(elements)):\n",
    "        e =e.append(get_elems_list(elements.loc[i], ecols), ignore_index=True)\n",
    "    print(e)\n",
    "    data['elements'] = e['elements']\n",
    "    return data\n",
    "\n",
    "def get_oth_props(df):\n",
    "    elements = get_elements(df)\n",
    "    ecols = elements.columns\n",
    "    data = df.drop(columns = ecols)\n",
    "    return data\n",
    "def get_chi_corrs(df, func, ind):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            try:\n",
    "                a  = []\n",
    "                a.append(r)\n",
    "                a.append(c)\n",
    "                pvalues[r][c] = round(func(df[a])[ind], 4)\n",
    "            except:\n",
    "                print('err here')\n",
    "    return pvalues\n",
    "\n",
    "def run_on_df(df, f):\n",
    "    a = pd.DataFrame()\n",
    "    for c in df.columns:\n",
    "        a[c] = f(df[c],0)\n",
    "    return a\n",
    "\n",
    "def get_heatmap(df):\n",
    "    return df.style.background_gradient(cmap='magma') \n",
    "\n",
    "def get_corrs(df, func, ind):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            pvalues[r][c] = round(func(df[r], df[c])[ind], 4)\n",
    "\n",
    "    return pvalues\n",
    "\n",
    "def calculate_pvalues(df):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            pvalues[r][c] = round(pearsonr(df[r], df[c])[1], 4)\n",
    "    return pvalues\n",
    "\n",
    "def notnulls(data, col):\n",
    "    return data[data[col].notnull()][col]\n",
    "\n",
    "def get_counts_df(data):\n",
    "    return pd.DataFrame(data.count()).transpose()\n",
    "\n",
    "def numerify_df(data):\n",
    "    print(\"HI\")\n",
    "    for c in data.columns:\n",
    "        try:\n",
    "            data[c] = data[c].astype(float)\n",
    "        except:\n",
    "            data = data.drop(columns=c)\n",
    "            print(c)\n",
    "    return data\n",
    "\n",
    "def drop_txt_rows(data):\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype ==object:\n",
    "            data = data.drop(col, axis=1)  \n",
    "    data = data.fillna(0)\n",
    "    return data\n",
    "\n",
    "def get_elements(df):\n",
    "    new_cols = []\n",
    "    for c in df.columns:\n",
    "        if len(c)<3:\n",
    "            if c is not 'A5' and c is not 'Rm':\n",
    "                new_cols.append(c)\n",
    "            \n",
    "    return df[new_cols]\n",
    "\n",
    "def get_pwr_corrs(df, func):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            if r==c:\n",
    "                pvalues[r][c]=0\n",
    "            else:\n",
    "                pvalues[r][c] = round(np.mean(get_power(df, r, c, func)[0]), 4)\n",
    "\n",
    "    return pvalues\n",
    "\n",
    "def mergecols(df, a ,b):\n",
    "    df['Category'] = df['Category'].replace(a,b)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the data from the different datasets\n",
    "new_data = pd.read_csv('02_23_newdata.csv').drop(columns='Unnamed: 0')\n",
    "linc_data = pd.read_csv('02_23_lincdata.csv').drop(columns='Unnamed: 0')\n",
    "weld_data = pd.read_csv('02_23_welddata.csv').drop(columns='Unnamed: 0')\n",
    "#cit_data = pd.read_csv('data/cit_data/200124_cit_data.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n",
    "new_data['UTS'] = new_data['UTS'].combine(new_data['UTS(Kg/mm2)'], take_smaller)\n",
    "new_data = new_data.drop(columns={'UTS(Kg/mm2)','Elong %'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns = ['Diffusible Hydrogen', 'Moisture', 'Yield strength', 'Tensile', 'Hardness',\n",
    "       'Ferrite (Fn)', 'Hardness_Scale', 'V', 'C', 'Cr', 'Mn', 'Mo', 'Ni',\n",
    "       'P ', 'S ', 'Si ', 'Cb', 'Cu', 'Category', 'Elongation']\n",
    "\n",
    "linc_data.columns = ['As', 'C', 'Charpy', 'Cr', 'Cu', 'Diffusible Hydrogen', 'Elongation',\n",
    "       'Lateral', 'Mn', 'Mn + Ni + Cr + Mo + V', 'Mo', 'N', 'Nb', 'Ni',\n",
    "       'Ni+Mn', 'P', 'P S', 'S', 'S Ni', 'SN', 'Si', 'Si P', 'Sn', 'Tensile',\n",
    "       'V', 'Yield strength', 'aws', 'conformances', 'ind', 'key features',\n",
    "       'requirements', 'typic_results', 'typical applications', 'Category',\n",
    "       'name', 'url']\n",
    "\n",
    "new_data = new_data.append(linc_data, ignore_index=True, sort=False)\n",
    "new_data = new_data.append(weld_data, ignore_index=True, sort=False)\n",
    "#new_data = new_data.append(cit_data, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticks = ['7018.0', '  6013 (REST)', '  LOTHERME', '  LOW ALLOY(SPL)', '  ST. STEELS', 'stainless-high-alloy', 'SMAW Stick Electrodes', 'stick-electrodes', '  6013 (NORMA-V)']\n",
    "\n",
    "for s in sticks:\n",
    "    new_data['Category'] = new_data['Category'].replace(s,'Stick')\n",
    "\n",
    "for u in range(0, len(new_data['Category'].unique())):\n",
    "    new_data['Category'] = new_data['Category'].replace(new_data['Category'].unique()[u],u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.dropna(axis=1, thresh=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#O means stick, 1 means other\n",
    "new_data['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n",
      "HI\n",
      "Hardness_Scale\n",
      "aws\n",
      "conformances\n",
      "key features\n",
      "requirements\n",
      "typic_results\n",
      "typical applications\n",
      "name\n",
      "url\n",
      "AWS\n",
      "Applications\n",
      "DIN\n",
      "Heat_Treated_As\n",
      "ISO\n",
      "Name\n",
      "Properties\n",
      "Redrying_Temp\n",
      "Suitable_For\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(\"final_numeric_data.csv\").drop(columns = {'Unnamed: 0'})\n",
    "df = new_data\n",
    "elems = get_elements(df).drop(columns={'A5', 'Rm'})\n",
    "elem_cols = elems.columns\n",
    "elems = numerify_df(elems).astype(float).to_numpy()\n",
    "elems[elems==0] = np.nan\n",
    "df = numerify_df(df).astype(float)\n",
    "columns = list(df.columns)\n",
    "df = df.to_numpy()\n",
    "df[df==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_err(df,prop, model):\n",
    "    tmp = np.concatenate([elems, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    #tmp[tmp==0] = np.nan\n",
    "    #tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "    lin_reg = model\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    pred = lin_reg.predict(X_test)\n",
    "    err = sqrt(mean_squared_error(y_test, pred))\n",
    "    return err\n",
    "\n",
    "def get_model_residual(df,prop, model):\n",
    "    tmp = np.concatenate([elems, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    #tmp[tmp==0] = np.nan\n",
    "    #tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "    #Trying data transformation\n",
    "    X_train = X_train+0.0000000000000001\n",
    "    X_test = X_test+0.0000000000000001\n",
    "    X_train = np.power(X_train,-.2)\n",
    "    X_test = np.power(X_test,-.2)\n",
    "    lin_reg = ResidualsPlot(model)\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    lin_reg.score(X_test, y_test)\n",
    "    return lin_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_model_err() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2b0686e3d0b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_model_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Category\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_model_err() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "get_model_err(df, \"Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " ...\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "print(df[:,columns.index(columns[2])].reshape(3255,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_model(model):\n",
    "    cats = [1, 2, 3, 4, 17, 18]\n",
    "    a = []\n",
    "    for i in cats:\n",
    "        err = get_model_err(df, columns[i],model)\n",
    "        a.append(err)\n",
    "    i = 0\n",
    "    for c in a:\n",
    "        print(columns[i] +\" \"+str(c))\n",
    "        i+=1\n",
    "    return a\n",
    "        \n",
    "def get_res_plots(model):\n",
    "    a = []\n",
    "    for i in range (0,16):\n",
    "        err = get_model_residual(df, columns[i],model)\n",
    "        print(columns[i])\n",
    "        err.show()\n",
    "        a.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HRC', 'BHN', 'RC', nan, 'VPN'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Hardness_Scale'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ensemble' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-7a9175b556eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtry_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ensemble' is not defined"
     ]
    }
   ],
   "source": [
    "try_model(ensemble.RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:18:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:18:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:18:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:18:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:18:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:18:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Diffusible Hydrogen 0.025769667260061555\n",
      "Moisture 43.584973200786564\n",
      "Yield strength 76.17510628210505\n",
      "Tensile 33.75390072534243\n",
      "Hardness 0.2508630262547021\n",
      "Ferrite (Fn) 5.326949167451765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.025769667260061555,\n",
       " 43.584973200786564,\n",
       " 76.17510628210505,\n",
       " 33.75390072534243,\n",
       " 0.2508630262547021,\n",
       " 5.326949167451765]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_model(xgb.XGBRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = try_model(svm.SVR(kernel = 'linear', C=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:20:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:20:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:20:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:20:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:20:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Diffusible Hydrogen 0.025769667260061555\n",
      "Moisture 43.584973200786564\n",
      "Yield strength 76.17510628210505\n",
      "Tensile 33.75390072534243\n",
      "Hardness 0.2508630262547021\n",
      "Ferrite (Fn) 5.326949167451765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.025769667260061555,\n",
       " 43.584973200786564,\n",
       " 76.17510628210505,\n",
       " 33.75390072534243,\n",
       " 0.2508630262547021,\n",
       " 5.326949167451765]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_model(XGBRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_mod(model):\n",
    "    a = []\n",
    "    cats = [1, 2, 3, 4, 17, 18]\n",
    "    for i in cats:\n",
    "        err = get_model_err(df, columns[i],model)\n",
    "        a.append(err)\n",
    "    i = 0\n",
    "    for c in a:\n",
    "        if c<1:\n",
    "            print(columns[i] +\" \"+str(c))\n",
    "        i+=1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperopt sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# XGB parameters\n",
    "xgb_reg_params = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "    'silent':True,\n",
    "}\n",
    "xgb_fit_params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "xgb_para = dict()\n",
    "xgb_para['reg_params'] = xgb_reg_params\n",
    "xgb_para['fit_params'] = xgb_fit_params\n",
    "xgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n",
    "\n",
    "\n",
    "# LightGBM parameters\n",
    "lgb_reg_params = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "}\n",
    "lgb_fit_params = {\n",
    "    'eval_metric': 'l2',\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "lgb_para = dict()\n",
    "lgb_para['reg_params'] = lgb_reg_params\n",
    "lgb_para['fit_params'] = lgb_fit_params\n",
    "lgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n",
    "\n",
    "\n",
    "# CatBoost parameters\n",
    "ctb_reg_params = {\n",
    "    'learning_rate':     hp.choice('learning_rate',     np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':         hp.choice('max_depth',         np.arange(5, 16, 1, dtype=int)),\n",
    "    'colsample_bylevel': hp.choice('colsample_bylevel', np.arange(0.3, 0.8, 0.1)),\n",
    "    'n_estimators':      100,\n",
    "    'eval_metric':       'RMSE',\n",
    "}\n",
    "ctb_fit_params = {\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "ctb_para = dict()\n",
    "ctb_para['reg_params'] = ctb_reg_params\n",
    "ctb_para['fit_params'] = ctb_fit_params\n",
    "ctb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HPOpt(object):\n",
    "\n",
    "    def __init__(self, x_train, x_test, y_train, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test  = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test  = y_test\n",
    "\n",
    "    def process(self, fn_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        return result, trials\n",
    "\n",
    "    def xgb_reg(self, para):\n",
    "        reg = xgb.XGBRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def lgb_reg(self, para):\n",
    "        reg = lgb.LGBMRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def ctb_reg(self, para):\n",
    "        reg = ctb.CatBoostRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def train_reg(self, reg, para):\n",
    "        reg.fit(self.x_train, self.y_train,\n",
    "                eval_set=[(self.x_train, self.y_train), (self.x_test, self.y_test)],\n",
    "                **para['fit_params'])\n",
    "        pred = reg.predict(self.x_test)\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_hpt_err(df,prop):\n",
    "    tmp = np.concatenate([elems, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    #tmp[tmp==0] = np.nan\n",
    "    #tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "    \n",
    "    obj = HPOpt(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    xgb_opt = obj.process(fn_name='xgb_reg', space=xgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
    "    #lgb_opt = obj.process(fn_name='lgb_reg', space=lgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
    "    #ctb_opt = obj.process(fn_name='ctb_reg', space=ctb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
    "\n",
    "    #lin_reg = model\n",
    "    #lin_reg.fit(X_train, y_train)\n",
    "    pred = xgb_opt[0]\n",
    "    #err = mean_squared_error(y_test, pred)\n",
    "    #return err\n",
    "    print(xgb_opt)\n",
    "def try_hpt_model():\n",
    "    a = []\n",
    "    cats = [1, 2, 3, 4, 17, 18]\n",
    "    for i in cats:\n",
    "        get_model_hpt_err(df, columns[i])\n",
    "        #a.append(err)\n",
    "    i = 0\n",
    "    for c in a:\n",
    "        if c<1:\n",
    "            print(columns[i] +\" \"+str(c))\n",
    "        i+=1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.29trial/s, best loss: 0.32374674395068204]\n",
      "({'colsample_bytree': 4, 'learning_rate': 5, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.898586390467096}, <hyperopt.base.Trials object at 0x7f4cfcb23450>)\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nbest models\\n[\\n1.669486962896262,\\n 645.1753925871617,\\n 0.10312447449675048,\\n 103.18961459947872,\\n 5484.029874187485,\\n 0.09797263577499045,\\n 967.1274838775004,\\n 0.263335535060129,\\n 4771.860175168826,\\n 9.09314420400554,\\n 720.1518897794107,\\n 564778.1503883341,\\n 5913.003492349578,\\n 43391.39032373773,\\n 6480.6171853828355,\\n 32672.351943018894]\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(get_model_hpt_err(df, \"Category\"))\n",
    "\"\"\"\n",
    "best models\n",
    "[\n",
    "1.669486962896262,\n",
    " 645.1753925871617,\n",
    " 0.10312447449675048,\n",
    " 103.18961459947872,\n",
    " 5484.029874187485,\n",
    " 0.09797263577499045,\n",
    " 967.1274838775004,\n",
    " 0.263335535060129,\n",
    " 4771.860175168826,\n",
    " 9.09314420400554,\n",
    " 720.1518897794107,\n",
    " 564778.1503883341,\n",
    " 5913.003492349578,\n",
    " 43391.39032373773,\n",
    " 6480.6171853828355,\n",
    " 32672.351943018894]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9057233601445844"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.gaussian_process as gp\n",
    "kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\n",
    "model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=True)\n",
    "get_model_err(df, \"Category\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
    "from sklearn import datasets\n",
    " \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'logistic_regression': LogisticRegression,\n",
    "    'rf': RandomForestRegressor,\n",
    "    'knn': KNeighborsRegressor, 'svr': SVR,\n",
    "    'xgb': XGBRegressor\n",
    "}\n",
    "\n",
    "\n",
    "def search_space(model):\n",
    "\n",
    "    model = model.lower()\n",
    "    space = {}\n",
    "\n",
    "    if model == 'knn':\n",
    "        space = {'n_neighbors': hp.choice('n_neighbors', range(1, 100)), 'scale': hp.choice('scale', [0, 1]),         'normalize': hp.choice('normalize', [0, 1]),\n",
    "\n",
    "\n",
    "                 }\n",
    "\n",
    "    elif model == 'xgb':\n",
    "        space = {'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "    'silent':True,\n",
    "                 }\n",
    "\n",
    "    elif model == 'svr':\n",
    "        space = {\n",
    "            'C': hp.uniform('C', 0, 20),\n",
    "            'kernel': hp.choice('kernel', ['linear', 'sigmoid', 'poly', 'rbf']),\n",
    "            'gamma': hp.uniform('gamma', 0, 20),\n",
    "            'scale': hp.choice('scale', [0, 1]),\n",
    "            'normalize': hp.choice('normalize', [0, 1]),\n",
    "        }\n",
    "\n",
    "    elif model == 'logistic_regression':\n",
    "        space = {\n",
    "            'warm_start': hp.choice('warm_start', [True, False]),\n",
    "            'fit_intercept': hp.choice('fit_intercept', [True, False]),\n",
    "            'tol': hp.uniform('tol', 0.00001, 0.0001),\n",
    "            'C': hp.uniform('C', 0.05, 3),\n",
    "            'solver': hp.choice('solver', ['newton-cg', 'lbfgs', 'liblinear']),\n",
    "            'max_iter': hp.choice('max_iter', range(100, 1000)),\n",
    "            'scale': hp.choice('scale', [0, 1]),\n",
    "            'normalize': hp.choice('normalize', [0, 1]),\n",
    "            'multi_class': 'auto',\n",
    "            'class_weight': 'balanced'\n",
    "        }\n",
    "    elif model == 'rf':\n",
    "        space = {'max_depth': hp.choice('max_depth', range(1, 20)),\n",
    "                 'max_features': hp.choice('max_features', range(1, 10)),\n",
    "                 'n_estimators': hp.choice('n_estimators', range(10, 50)),\n",
    "                 'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "                 }\n",
    "    space['model'] = model\n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_status(clf,X_,y):\n",
    "    acc = cross_val_score(clf, X_, y, cv=5).mean() \n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "def obj_fnc(params) : \n",
    "    model = params.get('model').lower()\n",
    "    X_ = scale_normalize(params,X[:])\n",
    "    del params['model']\n",
    "    clf = models[model](**params, 'objective': 'reg:squarederror',)\n",
    "    return(get_acc_status(clf,X_,y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import space_eval\n",
    "kf = KFold(n_splits=5, random_state=42)\n",
    "curmodel = XGBRegressor\n",
    "curvar = \"Category\"\n",
    "dataset = 1\n",
    "def get_data(prop):\n",
    "    tmp = np.concatenate([elems, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    #tmp[tmp==0] = np.nan\n",
    "    #tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.333, random_state=42, shuffle=True)\n",
    "    return x_val, x_test, x_train, y_val, y_test, y_train\n",
    "\n",
    "def objective(space):\n",
    "    #print(space)\n",
    "    clf = curmodel(\n",
    "                           **space, objective = 'reg:squarederror'\n",
    "                            )\n",
    "\n",
    "    \n",
    "    x_val, x_test, x_train, y_val, y_test, y_train = get_data(curvar)\n",
    "    \n",
    "    eval_set  = [( x_train, y_train), ( x_val, y_val)]\n",
    "\n",
    "    clf.fit(x_train, y_train,\n",
    "            eval_set=eval_set, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "\n",
    "    pred = clf.predict(x_test)\n",
    "    mse_scr = -cross_val_score(clf, x_train, y_train, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "    #print (\"SCORE:\", np.sqrt(mean_squared_error(y_test, pred)))\n",
    "    #change the metric if you like\n",
    "    return {'loss':np.sqrt(mse_scr), 'status': STATUS_OK }\n",
    "\n",
    "def run_opt(prop, space):\n",
    "\n",
    "    curmodel = models[space]\n",
    "    curvar = prop\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=objective,\n",
    "                space=search_space(space),\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=10,\n",
    "                trials=trials,\n",
    "               return_argmin=False)\n",
    "    \n",
    "    #params = space_eval(search_space(space), best)\n",
    "\n",
    "    \n",
    "    curmodel = curmodel(**best)\n",
    "    x_val, x_test, x_train, y_val, y_test, y_train = get_data(prop)\n",
    "\n",
    "    eval_set  = [( x_train, y_train), ( x_test, y_test)]\n",
    "    if space is 'xgb':\n",
    "        curmodel.fit(x_train, y_train,\n",
    "                    eval_set=eval_set, eval_metric=\"rmse\",\n",
    "                    early_stopping_rounds=10,verbose=False)\n",
    "    else:\n",
    "        curmodel.fit(x_train, y_train)\n",
    "    pred = curmodel.predict(x_test)\n",
    "    mse_scr = np.sqrt(mean_squared_error(y_test, pred))\n",
    "\n",
    "    return mse_scr, trials.best_trial['result']['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.95trial/s, best loss: 0.3617257116506841]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-ba8164460ea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Category\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'knn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-147-a7816ce31eb1>\u001b[0m in \u001b[0;36mrun_opt\u001b[0;34m(prop, space)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mcurmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/regression.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_neighbors, weights, algorithm, leaf_size, p, metric, metric_params, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m               \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m               \u001b[0mleaf_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleaf_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m               metric_params=metric_params, n_jobs=n_jobs, **kwargs)\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'model'"
     ]
    }
   ],
   "source": [
    "err, val, = run_opt(\"Category\", 'knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(626, 21)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(\"Category\")[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Diffusible Hydrogen',\n",
       " 'Moisture',\n",
       " 'Yield strength',\n",
       " 'Tensile',\n",
       " 'Hardness',\n",
       " 'Ferrite (Fn)',\n",
       " 'V',\n",
       " 'C',\n",
       " 'Cr',\n",
       " 'Mn',\n",
       " 'Mo',\n",
       " 'Ni',\n",
       " 'P ',\n",
       " 'S ',\n",
       " 'Si ',\n",
       " 'Cb',\n",
       " 'Cu',\n",
       " 'Category',\n",
       " 'Elongation',\n",
       " 'Charpy',\n",
       " 'P',\n",
       " 'S',\n",
       " 'Si',\n",
       " 'ind',\n",
       " 'A5',\n",
       " 'DIN_W',\n",
       " 'Fe',\n",
       " 'HT_Temp',\n",
       " 'IE-20',\n",
       " 'IE-40',\n",
       " 'IE-60',\n",
       " 'Redry_Time',\n",
       " 'Rm',\n",
       " 'Rp0']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V', 'C', 'Cr', 'Mn', 'Mo', 'Ni', 'P ', 'S ', 'Cb', 'Cu', 'P', 'S',\n",
       "       'Si', 'Fe'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
