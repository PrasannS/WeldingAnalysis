{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ast, json\n",
    "import math\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.stats import weightstats as stests\n",
    "import scipy.stats as scs\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as stats\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as ctb\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
    "from sklearn import datasets\n",
    " \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful methods\n",
    "def numerify_df(data):\n",
    "    for c in data.columns:\n",
    "        try:\n",
    "            data[c] = data[c].astype(float)\n",
    "        except:\n",
    "            data = data.drop(columns=c)\n",
    "    return data\n",
    "\n",
    "def get_elements(df):\n",
    "    new_cols = []\n",
    "    for c in df.columns:\n",
    "        if len(c)<3:\n",
    "            if c is not 'A5' and c is not 'Rm':\n",
    "                new_cols.append(c)\n",
    "            \n",
    "    return df[new_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_data():\n",
    "    #Load initial data\n",
    "    new_data = pd.read_csv('../data/final_data/02_23_newdata.csv').drop(columns='Unnamed: 0')\n",
    "    new_data['Category'] = 'Stick'\n",
    "    print(\"NEW DATA\" + str(new_data.shape))\n",
    "    linc_data = pd.read_csv('../data/final_data/02_23_lincdata.csv').drop(columns='Unnamed: 0')\n",
    "    print(\"LINC DATA\" + str(linc_data.shape))\n",
    "    weld_data = pd.read_csv('../data/final_data/02_23_welddata.csv').drop(columns='Unnamed: 0')\n",
    "    print(\"CEWELD DATA\" + str(weld_data.shape))\n",
    "    cit_data = pd.read_csv('../data/cit_data/200124_cit_data.csv').drop(columns='Unnamed: 0')\n",
    "    print(\"CIT DATA\" + str(cit_data.shape))\n",
    "    \n",
    "    take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n",
    "    new_data['UTS'] = new_data['UTS'].combine(new_data['UTS(Kg/mm2)'], take_smaller)\n",
    "    new_data = new_data.drop(columns={'UTS(Kg/mm2)','Elong %'})\n",
    "    \n",
    "    \n",
    "    #line up datasets and merge them\n",
    "    new_data.columns = ['Diffusible Hydrogen', 'Moisture', 'Yield strength', 'Tensile', 'Hardness',\n",
    "           'Ferrite (Fn)', 'Hardness_Scale', 'V', 'C', 'Cr', 'Mn', 'Mo', 'Ni',\n",
    "           'P ', 'S ', 'Si', 'Cb', 'Cu', 'Category', 'Elongation']\n",
    "\n",
    "    linc_data.columns = ['As', 'C', 'Charpy', 'Cr', 'Cu', 'Diffusible Hydrogen', 'Elongation',\n",
    "           'Lateral', 'Mn', 'Mn + Ni + Cr + Mo + V', 'Mo', 'N', 'Nb', 'Ni',\n",
    "           'Ni+Mn', 'P', 'P S', 'S', 'S Ni', 'SN', 'Si', 'Si P', 'Sn', 'Tensile',\n",
    "           'V', 'Yield strength', 'aws', 'conformances', 'ind', 'key features',\n",
    "           'requirements', 'typic_results', 'typical applications', 'Category',\n",
    "           'name', 'url']\n",
    "\n",
    "    new_data = new_data.append(linc_data, ignore_index=True, sort=False)\n",
    "    new_data = new_data.append(weld_data, ignore_index=True, sort=False)\n",
    "    new_data = new_data.append(cit_data, ignore_index=True, sort=False)\n",
    "    \n",
    "    \n",
    "    #Merging Stick Columns\n",
    "    sticks = ['7018.0', '  6013 (REST)', '  LOTHERME', '  LOW ALLOY(SPL)', '  ST. STEELS', 'stainless-high-alloy', 'SMAW Stick Electrodes', 'stick-electrodes', '  6013 (NORMA-V)']\n",
    "\n",
    "    for s in sticks:\n",
    "        new_data['Category'] = new_data['Category'].replace(s,'Stick')\n",
    "    \n",
    "    #Identifying Stick and non-Stick\n",
    "    uns = new_data['Category'].unique()[1:]\n",
    "    for u in uns:\n",
    "        new_data['Category'] = new_data['Category'].replace(u,\"Others\")\n",
    "        new_data['Category'].unique()\n",
    "    uns = new_data['Category'].unique()\n",
    "\n",
    "    i = 0\n",
    "    for u in uns:\n",
    "        new_data['Category'] = new_data['Category'].replace(u,1-i)\n",
    "        i = i+1\n",
    "    \n",
    "    #1 means stick, 0 means other\n",
    "    new_data = new_data.drop(columns={'ind'})\n",
    "    new_data = new_data.dropna(axis=1, thresh=100)\n",
    "    \n",
    "    \n",
    "    return new_data\n",
    "\n",
    "#If true it will only return stick dataset\n",
    "def get_ml_data(stick):\n",
    "    #Get merged dataset\n",
    "    df = get_merged_data()\n",
    "    \n",
    "    \n",
    "    #Get training dataset\n",
    "    df = numerify_df(df).astype(float)\n",
    "    columns = list(df.columns)\n",
    "    df = df.to_numpy()\n",
    "    \n",
    "    #Getting rid of non-sticks\n",
    "    df[df==0] = np.nan\n",
    "    if stick:\n",
    "        df = df[pd.notnull(df[:,columns.index(\"Category\")])]\n",
    "    \n",
    "    tmp = pd.DataFrame(df, columns = columns)\n",
    "    elems = get_elements(tmp).drop(columns={'A5', 'Rm'})\n",
    "    elem_cols = elems.columns\n",
    "    elems = numerify_df(elems).astype(float).to_numpy()\n",
    "    elems[elems==0] = np.nan\n",
    "    \n",
    "    \n",
    "        \n",
    "    return df, elems, elem_cols, columns\n",
    "\n",
    "#Getting all of the columns of parameters to predict\n",
    "def get_pred_cols():\n",
    "    pred_cs = ['Rm', 'A5']\n",
    "    for c in columns:\n",
    "        if len(c)>2:\n",
    "            pred_cs.append(c)\n",
    "    return pred_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods for pre-examining data\n",
    "\n",
    "def get_model_err(df,prop, model):\n",
    "    tmp = np.concatenate([elems, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    #tmp[tmp==0] = np.nan\n",
    "    #tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "    lin_reg = model\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    pred = lin_reg.predict(X_test)\n",
    "    err = sqrt(mean_squared_error(y_test, pred))\n",
    "    return err\n",
    "\n",
    "def get_model_residual(df,prop, model):\n",
    "    tmp = np.concatenate([elems, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    #tmp[tmp==0] = np.nan\n",
    "    #tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "    #Trying data transformation\n",
    "    X_train = X_train+0.0000000000000001\n",
    "    X_test = X_test+0.0000000000000001\n",
    "    X_train = np.power(X_train,-.2)\n",
    "    X_test = np.power(X_test,-.2)\n",
    "    lin_reg = ResidualsPlot(model)\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    lin_reg.score(X_test, y_test)\n",
    "    return lin_reg\n",
    "\n",
    "def try_model(model):\n",
    "    a = []\n",
    "    for c in get_pred_cols():\n",
    "        err = get_model_err(df, c,model)\n",
    "        a.append(err)\n",
    "    i = 0\n",
    "    for c in a:\n",
    "        print(columns[i] +\" \"+str(c))\n",
    "        i+=1\n",
    "    return a\n",
    "        \n",
    "def get_res_plots(model):\n",
    "    a = []\n",
    "    for c in get_pred_cols():\n",
    "        err = get_model_residual(df, c,model)\n",
    "        print(columns[i])\n",
    "        err.show()\n",
    "        a.append(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW DATA(1509, 22)\n",
      "LINC DATA(944, 36)\n",
      "CEWELD DATA(678, 51)\n",
      "CIT DATA(1650, 75)\n"
     ]
    }
   ],
   "source": [
    "df, elems, elem_cols, columns = get_ml_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasann/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusible Hydrogen 83.77677674663482\n",
      "Moisture 2.6074987141661166\n",
      "Yield strength 0.4946381614364334\n",
      "Tensile 0.015895286243181157\n",
      "Ferrite (Fn) 81.76462319130242\n",
      "V 94.79607525540142\n",
      "C 0.8729046887868843\n",
      "Cr 0.0\n",
      "Mn 4.575317728629353\n",
      "Mo 20.853747011842042\n",
      "Ni 0.12641470039089994\n",
      "P  26.306324853022083\n",
      "S  27.879341841356997\n",
      "Si 17.436154640182668\n",
      "Cb 8.557113727405342\n",
      "Cu 0.17079524472680122\n",
      "Category 8497.952727020938\n",
      "Elongation 0.0\n",
      "Charpy 0.0\n",
      "P 0.0\n",
      "S 0.0\n",
      "A5 0.0\n",
      "Co 0.0\n",
      "DIN_W 0.0\n",
      "Fe 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[83.77677674663482,\n",
       " 2.6074987141661166,\n",
       " 0.4946381614364334,\n",
       " 0.015895286243181157,\n",
       " 81.76462319130242,\n",
       " 94.79607525540142,\n",
       " 0.8729046887868843,\n",
       " 0.0,\n",
       " 4.575317728629353,\n",
       " 20.853747011842042,\n",
       " 0.12641470039089994,\n",
       " 26.306324853022083,\n",
       " 27.879341841356997,\n",
       " 17.436154640182668,\n",
       " 8.557113727405342,\n",
       " 0.17079524472680122,\n",
       " 8497.952727020938,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_model(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = try_model(svm.SVR(kernel = 'linear', C=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:20:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:20:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:20:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:20:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:20:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Diffusible Hydrogen 0.025769667260061555\n",
      "Moisture 43.584973200786564\n",
      "Yield strength 76.17510628210505\n",
      "Tensile 33.75390072534243\n",
      "Hardness 0.2508630262547021\n",
      "Ferrite (Fn) 5.326949167451765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.025769667260061555,\n",
       " 43.584973200786564,\n",
       " 76.17510628210505,\n",
       " 33.75390072534243,\n",
       " 0.2508630262547021,\n",
       " 5.326949167451765]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_model(XGBRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Hyperopt code sample 1\n",
    "\n",
    "# XGB parameters\n",
    "xgb_reg_params = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "    'silent':True,\n",
    "}\n",
    "xgb_fit_params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "xgb_para = dict()\n",
    "xgb_para['reg_params'] = xgb_reg_params\n",
    "xgb_para['fit_params'] = xgb_fit_params\n",
    "xgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n",
    "\n",
    "\n",
    "# LightGBM parameters\n",
    "lgb_reg_params = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "}\n",
    "lgb_fit_params = {\n",
    "    'eval_metric': 'l2',\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "lgb_para = dict()\n",
    "lgb_para['reg_params'] = lgb_reg_params\n",
    "lgb_para['fit_params'] = lgb_fit_params\n",
    "lgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n",
    "\n",
    "\n",
    "# CatBoost parameters\n",
    "ctb_reg_params = {\n",
    "    'learning_rate':     hp.choice('learning_rate',     np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':         hp.choice('max_depth',         np.arange(5, 16, 1, dtype=int)),\n",
    "    'colsample_bylevel': hp.choice('colsample_bylevel', np.arange(0.3, 0.8, 0.1)),\n",
    "    'n_estimators':      100,\n",
    "    'eval_metric':       'RMSE',\n",
    "}\n",
    "ctb_fit_params = {\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "ctb_para = dict()\n",
    "ctb_para['reg_params'] = ctb_reg_params\n",
    "ctb_para['fit_params'] = ctb_fit_params\n",
    "ctb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HPOpt(object):\n",
    "\n",
    "    def __init__(self, x_train, x_test, y_train, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test  = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test  = y_test\n",
    "\n",
    "    def process(self, fn_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        return result, trials\n",
    "\n",
    "    def xgb_reg(self, para):\n",
    "        reg = xgb.XGBRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def lgb_reg(self, para):\n",
    "        reg = lgb.LGBMRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def ctb_reg(self, para):\n",
    "        reg = ctb.CatBoostRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def train_reg(self, reg, para):\n",
    "        reg.fit(self.x_train, self.y_train,\n",
    "                eval_set=[(self.x_train, self.y_train), (self.x_test, self.y_test)],\n",
    "                **para['fit_params'])\n",
    "        pred = reg.predict(self.x_test)\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_hpt_err(df,prop):\n",
    "    tmp = np.concatenate([elems, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    #tmp[tmp==0] = np.nan\n",
    "    #tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "    \n",
    "    obj = HPOpt(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    xgb_opt = obj.process(fn_name='xgb_reg', space=xgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
    "    #lgb_opt = obj.process(fn_name='lgb_reg', space=lgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
    "    #ctb_opt = obj.process(fn_name='ctb_reg', space=ctb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
    "\n",
    "    #lin_reg = model\n",
    "    #lin_reg.fit(X_train, y_train)\n",
    "    pred = xgb_opt[0]\n",
    "    #err = mean_squared_error(y_test, pred)\n",
    "    #return err\n",
    "    print(xgb_opt)\n",
    "    \n",
    "def try_hpt_model():\n",
    "    a = []\n",
    "    cats = [1, 2, 3, 4, 17, 18]\n",
    "    for i in cats:\n",
    "        get_model_hpt_err(df, columns[i])\n",
    "        #a.append(err)\n",
    "    i = 0\n",
    "    for c in a:\n",
    "        if c<1:\n",
    "            print(columns[i] +\" \"+str(c))\n",
    "        i+=1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 17.55trial/s, best loss: 1.1920928955078125e-07]\n",
      "({'colsample_bytree': 0, 'learning_rate': 4, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.8977608652442637}, <hyperopt.base.Trials object at 0x7f827239a8d0>)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(get_model_hpt_err(df, \"Charpy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-66333039574b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstantKernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRBF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianProcessRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_model_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Charpy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-c81562ed168b>\u001b[0m in \u001b[0;36mget_model_err\u001b[0;34m(df, prop, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlin_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mlin_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlin_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    234\u001b[0m                     optima.append(\n\u001b[1;32m    235\u001b[0m                         self._constrained_optimization(obj_func, theta_initial,\n\u001b[0;32m--> 236\u001b[0;31m                                                        bounds))\n\u001b[0m\u001b[1;32m    237\u001b[0m             \u001b[0;31m# Select result from run with minimal (negative) log-marginal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;31m# likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fmin_l_bfgs_b\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mtheta_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvergence_dict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m                 \u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvergence_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                 warnings.warn(\"fmin_l_bfgs_b terminated abnormally with the \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     lml, grad = self.log_marginal_likelihood(\n\u001b[0;32m--> 213\u001b[0;31m                         theta, eval_gradient=True)\n\u001b[0m\u001b[1;32m    214\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# compare Equation 5.9 from GPML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ik,jk->ijk\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# k: output-dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mcho_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;31m# Compute \"0.5 * trace(tmp.dot(K_gradient))\" without\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;31m# constructing the full matrix tmp.dot(K_gradient) since only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcho_solve\u001b[0;34m(c_and_lower, b, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mpotrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'potrs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpotrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError('illegal value in %d-th argument of internal potrs'\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#trying out Gaussian Processes\n",
    "import sklearn.gaussian_process as gp\n",
    "kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\n",
    "model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=True)\n",
    "get_model_err(df, \"Charpy\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization code 2\n",
    "\n",
    "models = {\n",
    "    'logistic_regression': LogisticRegression,\n",
    "    'rf': RandomForestRegressor,\n",
    "    'knn': KNeighborsRegressor, 'svr': SVR,\n",
    "    'xgb': XGBRegressor\n",
    "}\n",
    "\n",
    "\n",
    "def search_space(model):\n",
    "\n",
    "    model = model.lower()\n",
    "    space = {}\n",
    "\n",
    "    if model == 'knn':\n",
    "        space = {'n_neighbors': hp.choice('n_neighbors', range(1, 100)),\n",
    "\n",
    "\n",
    "                 }\n",
    "\n",
    "    elif model == 'xgb':\n",
    "        space = {'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "    'silent':True,\n",
    "                 }\n",
    "\n",
    "    elif model == 'svr':\n",
    "        space = {\n",
    "            'C': hp.uniform('C', 0, 20),\n",
    "            'kernel': hp.choice('kernel', ['linear', 'sigmoid', 'poly', 'rbf']),\n",
    "            'gamma': hp.uniform('gamma', 0, 20),\n",
    "            'scale': hp.choice('scale', [0, 1]),\n",
    "            'normalize': hp.choice('normalize', [0, 1]),\n",
    "        }\n",
    "\n",
    "    elif model == 'logistic_regression':\n",
    "        space = {\n",
    "            'warm_start': hp.choice('warm_start', [True, False]),\n",
    "            'fit_intercept': hp.choice('fit_intercept', [True, False]),\n",
    "            'tol': hp.uniform('tol', 0.00001, 0.0001),\n",
    "            'C': hp.uniform('C', 0.05, 3),\n",
    "            'solver': hp.choice('solver', ['newton-cg', 'lbfgs', 'liblinear']),\n",
    "            'max_iter': hp.choice('max_iter', range(100, 1000)),\n",
    "            'scale': hp.choice('scale', [0, 1]),\n",
    "            'normalize': hp.choice('normalize', [0, 1]),\n",
    "            'multi_class': 'auto',\n",
    "            'class_weight': 'balanced'\n",
    "        }\n",
    "    elif model == 'rf':\n",
    "        space = {'max_depth': hp.choice('max_depth', range(1, 20)),\n",
    "                 'max_features': hp.choice('max_features', range(1, 10)),\n",
    "                 'n_estimators': hp.choice('n_estimators', range(10, 50)),\n",
    "                 'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "                 }\n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import space_eval\n",
    "kf = KFold(n_splits=5, random_state=42)\n",
    "curmodel = XGBRegressor\n",
    "curvar = \"Category\"\n",
    "dataset = 1\n",
    "def get_data(prop):\n",
    "    tmp = np.concatenate([elems, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    tmp[tmp==0] = np.nan\n",
    "    tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.333, random_state=42, shuffle=True)\n",
    "    return x_val, x_test, x_train, y_val, y_test, y_train\n",
    "\n",
    "def objective(space):\n",
    "    #print(space)\n",
    "    clf = curmodel(\n",
    "                           **space, objective = 'reg:squarederror'\n",
    "                            )\n",
    "\n",
    "    \n",
    "    x_val, x_test, x_train, y_val, y_test, y_train = get_data(curvar)\n",
    "    \n",
    "    eval_set  = [( x_train, y_train), ( x_val, y_val)]\n",
    "\n",
    "    clf.fit(x_train, y_train,\n",
    "            eval_set=eval_set, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False,)\n",
    "\n",
    "    pred = clf.predict(x_test)\n",
    "    mse_scr = -cross_val_score(clf, x_train, y_train, cv=kf, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "    #print (\"SCORE:\", np.sqrt(mean_squared_error(y_test, pred)))\n",
    "    #change the metric if you like\n",
    "    pred = clf.predict(x_test)\n",
    "    score = np.sqrt(mean_squared_error(y_test, pred))\n",
    "    return {'loss':np.sqrt(mse_scr), 'status': STATUS_OK, 'sco':score }\n",
    "\n",
    "def get_model(space):\n",
    "    #print(space)\n",
    "    clf = curmodel(\n",
    "                           **space, objective = 'reg:squarederror'\n",
    "                            )\n",
    "\n",
    "    \n",
    "    x_val, x_test, x_train, y_val, y_test, y_train = get_data(curvar)\n",
    "    \n",
    "    eval_set  = [( x_train, y_train), ( x_val, y_val)]\n",
    "\n",
    "    clf.fit(x_train, y_train,\n",
    "            eval_set=eval_set, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False,)\n",
    "\n",
    "    pred = clf.predict(x_test)\n",
    "    mse_scr = -cross_val_score(clf, x_train, y_train, cv=kf, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "    #print (\"SCORE:\", np.sqrt(mean_squared_error(y_test, pred)))\n",
    "    #change the metric if you like\n",
    "    pred = clf.predict(x_test)\n",
    "    score = np.sqrt(mean_squared_error(y_test, pred))\n",
    "    return clf\n",
    "\n",
    "def run_opt(prop, space):\n",
    "\n",
    "    curmodel = models[space]\n",
    "    curvar = prop\n",
    "    trials = Trials()\n",
    "    \n",
    "    #TODO change max_evals to 100\n",
    "    best = fmin(fn=objective,\n",
    "                space=search_space(space),\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=10,\n",
    "                trials=trials,\n",
    "               return_argmin=False)\n",
    "    \n",
    "    return trials.best_trial['result']['loss'], trials.best_trial['result']['sco'], best\n",
    "\n",
    "def get_opt_model(prop, space):\n",
    "\n",
    "    #TODO Change max evals to 100\n",
    "    curmodel = models[space]\n",
    "    curvar = prop\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=objective,\n",
    "                space=search_space(space),\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=10,\n",
    "                trials=trials,\n",
    "               return_argmin=False)\n",
    "    \n",
    "    model = get_model(best)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_dataset_(prop):\n",
    "    tmp = np.concatenate([df, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    tmp[tmp==0] = np.nan\n",
    "    tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.50trial/s, best loss: 1.3423093046464597e-05]\n"
     ]
    }
   ],
   "source": [
    "val, los, mod = run_opt(\"Charpy\", 'logistic_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for getting benchmarks using hyperopt code 2\n",
    "def get_benchmarks():\n",
    "    d = pd.DataFrame()\n",
    "    a = {}\n",
    "    a['data'] = dataset\n",
    "    for m in models.keys():\n",
    "        print(m)\n",
    "        a['model'] = m\n",
    "        for c in get_pred_cols():\n",
    "            print(c)\n",
    "            a['column'] = c\n",
    "            a['validation'], a['test'], a['params'] = run_opt(c, m)\n",
    "            d = d.append(a, ignore_index=True, sort=False)\n",
    "    return d\n",
    "\n",
    "def get_models(prop):\n",
    "    d = []\n",
    "    for c in get_pred_cols():\n",
    "        d.append(get_opt_model(c, prop))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.50trial/s, best loss: -0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.72trial/s, best loss: -0.0]\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.82trial/s, best loss: -0.0]                \n",
      " 10%|█         | 1/10 [00:00<00:01,  5.81trial/s, best loss: -0.0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2b8173326145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#TODO Fix strange bug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-484a92effafa>\u001b[0m in \u001b[0;36mget_models\u001b[0;34m(prop)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_pred_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_opt_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-23822d315a0f>\u001b[0m in \u001b[0;36mget_opt_model\u001b[0;34m(prop, space)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                return_argmin=False)\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         )\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         )\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             )\n\u001b[0;32m--> 894\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-23822d315a0f>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(space)\u001b[0m\n\u001b[1;32m     29\u001b[0m     clf.fit(x_train, y_train,\n\u001b[1;32m     30\u001b[0m             \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmse\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             early_stopping_rounds=10,verbose=False,)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# check evaluation result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mbst_eval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst_eval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst_eval_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m   1170\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                                               \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m                                               ctypes.byref(msg)))\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TODO Fix strange bug\n",
    "xgb_models = get_models('xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n",
      "Rm\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.72trial/s, best loss: 1.33514404296875e-05]\n",
      "A5\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.30trial/s, best loss: 1.33514404296875e-05]\n",
      "Diffusible Hydrogen\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.43trial/s, best loss: 1.33514404296875e-05]\n",
      "Moisture\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.98trial/s, best loss: 1.33514404296875e-05]\n",
      "Yield strength\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.39trial/s, best loss: 1.33514404296875e-05]\n",
      "Tensile\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.45trial/s, best loss: 1.33514404296875e-05]\n",
      "Hardness\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.77trial/s, best loss: 1.33514404296875e-05]\n",
      "Ferrite (Fn)\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.46trial/s, best loss: 1.33514404296875e-05]\n",
      "Category\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.46trial/s, best loss: 1.33514404296875e-05]\n",
      "Elongation\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.05trial/s, best loss: 1.33514404296875e-05]\n",
      "Charpy\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.36trial/s, best loss: 1.33514404296875e-05]\n",
      "DIN_W\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.44trial/s, best loss: 1.33514404296875e-05]\n",
      "HT_Temp\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.92trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-20\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.35trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-40\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.40trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-60\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.81trial/s, best loss: 1.33514404296875e-05]\n",
      "Redry_Time\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.27trial/s, best loss: 1.33514404296875e-05]\n",
      "Rp0\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.45trial/s, best loss: 1.33514404296875e-05]\n",
      "rf\n",
      "Rm\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.50trial/s, best loss: 0.00394517183303833]\n",
      "A5\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.38trial/s, best loss: 0.002876877784729004]\n",
      "Diffusible Hydrogen\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.85trial/s, best loss: 0.004869699478149414]\n",
      "Moisture\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.44trial/s, best loss: 0.004869699478149414]\n",
      "Yield strength\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.64trial/s, best loss: 0.023617267608642578]\n",
      "Tensile\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.03trial/s, best loss: 0.003196239471435547]\n",
      "Hardness\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.12trial/s, best loss: 0.002876877784729004]\n",
      "Ferrite (Fn)\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.48trial/s, best loss: 0.003551006317138672]\n",
      "Category\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.84trial/s, best loss: 0.00394517183303833]\n",
      "Elongation\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.13trial/s, best loss: 0.003196239471435547]\n",
      "Charpy\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.54trial/s, best loss: 0.002876877784729004]\n",
      "DIN_W\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.77trial/s, best loss: 0.004869699478149414]\n",
      "HT_Temp\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.37trial/s, best loss: 0.00394517183303833]\n",
      "IE-20\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.51trial/s, best loss: 0.003551006317138672]\n",
      "IE-40\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.85trial/s, best loss: 0.006677985191345215]\n",
      "IE-60\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.96trial/s, best loss: 0.002876877784729004]\n",
      "Redry_Time\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.51trial/s, best loss: 0.004383087158203125]\n",
      "Rp0\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.03trial/s, best loss: 0.003196239471435547]\n",
      "knn\n",
      "Rm\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.64trial/s, best loss: 1.33514404296875e-05]\n",
      "A5\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.77trial/s, best loss: 1.33514404296875e-05]\n",
      "Diffusible Hydrogen\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.74trial/s, best loss: 1.33514404296875e-05]\n",
      "Moisture\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.80trial/s, best loss: 1.33514404296875e-05]\n",
      "Yield strength\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.70trial/s, best loss: 1.33514404296875e-05]\n",
      "Tensile\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.81trial/s, best loss: 1.33514404296875e-05]\n",
      "Hardness\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.82trial/s, best loss: 1.33514404296875e-05]\n",
      "Ferrite (Fn)\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.84trial/s, best loss: 1.33514404296875e-05]\n",
      "Category\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.82trial/s, best loss: 1.33514404296875e-05]\n",
      "Elongation\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.73trial/s, best loss: 1.33514404296875e-05]\n",
      "Charpy\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.72trial/s, best loss: 1.33514404296875e-05]\n",
      "DIN_W\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.65trial/s, best loss: 1.33514404296875e-05]\n",
      "HT_Temp\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.70trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-20\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.61trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-40\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.59trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-60\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.52trial/s, best loss: 1.33514404296875e-05]\n",
      "Redry_Time\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.66trial/s, best loss: 1.33514404296875e-05]\n",
      "Rp0\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.55trial/s, best loss: 1.33514404296875e-05]\n",
      "svr\n",
      "Rm\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.82trial/s, best loss: 1.33514404296875e-05]\n",
      "A5\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.77trial/s, best loss: 1.33514404296875e-05]\n",
      "Diffusible Hydrogen\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.87trial/s, best loss: 1.33514404296875e-05]\n",
      "Moisture\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.83trial/s, best loss: 1.33514404296875e-05]\n",
      "Yield strength\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.83trial/s, best loss: 1.33514404296875e-05]\n",
      "Tensile\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.75trial/s, best loss: 1.33514404296875e-05]\n",
      "Hardness\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.81trial/s, best loss: 1.33514404296875e-05]\n",
      "Ferrite (Fn)\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.73trial/s, best loss: 1.33514404296875e-05]\n",
      "Category\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.71trial/s, best loss: 1.33514404296875e-05]\n",
      "Elongation\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.76trial/s, best loss: 1.33514404296875e-05]\n",
      "Charpy\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.77trial/s, best loss: 1.33514404296875e-05]\n",
      "DIN_W\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.70trial/s, best loss: 1.33514404296875e-05]\n",
      "HT_Temp\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.77trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-20\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.81trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-40\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.87trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-60\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.92trial/s, best loss: 1.33514404296875e-05]\n",
      "Redry_Time\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.84trial/s, best loss: 1.33514404296875e-05]\n",
      "Rp0\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.84trial/s, best loss: 1.33514404296875e-05]\n",
      "xgb\n",
      "Rm\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.50trial/s, best loss: -0.0]                \n",
      "A5\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.34trial/s, best loss: -0.0]\n",
      "Diffusible Hydrogen\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.29trial/s, best loss: -0.0]\n",
      "Moisture\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.21trial/s, best loss: -0.0]                \n",
      "Yield strength\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.11trial/s, best loss: -0.0]                 \n",
      "Tensile\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.50trial/s, best loss: -0.0]                \n",
      "Hardness\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.34trial/s, best loss: -0.0]                \n",
      "Ferrite (Fn)\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.28trial/s, best loss: -0.0]                 \n",
      "Category\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.15trial/s, best loss: -0.0]\n",
      "Elongation\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.76trial/s, best loss: -0.0]                \n",
      "Charpy\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.86trial/s, best loss: -0.0]                 \n",
      "DIN_W\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.01trial/s, best loss: -0.0]                \n",
      "HT_Temp\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.69trial/s, best loss: -0.0]                \n",
      "IE-20\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.75trial/s, best loss: -0.0]               \n",
      "IE-40\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.81trial/s, best loss: -0.0]\n",
      "IE-60\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.70trial/s, best loss: -0.0]                \n",
      "Redry_Time\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.32trial/s, best loss: -0.0]                 \n",
      "Rp0\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.49trial/s, best loss: -0.0]\n"
     ]
    }
   ],
   "source": [
    "d = get_benchmarks()\n",
    "d.to_csv('../benchmarks/benchmark_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "973px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
