{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ast, json\n",
    "import math\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.stats import weightstats as stests\n",
    "import scipy.stats as scs\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as stats\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as ctb\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
    "from sklearn import datasets\n",
    " \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "\n",
    "import qgrid\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful methods\n",
    "def numerify_df(data):\n",
    "    for c in data.columns:\n",
    "        try:\n",
    "            data[c] = data[c].astype(float)\n",
    "        except:\n",
    "            data = data.drop(columns=c)\n",
    "    return data\n",
    "\n",
    "def get_elements(df):\n",
    "    new_cols = []\n",
    "    for c in df.columns:\n",
    "        if len(c)<3:\n",
    "            if c is not 'A5' and c is not 'Rm':\n",
    "                new_cols.append(c)\n",
    "            \n",
    "    return df[new_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_data():\n",
    "    #Load initial data\n",
    "    new_data = pd.read_csv('../data/final_data/02_23_newdata.csv').drop(columns='Unnamed: 0')\n",
    "    new_data['Category'] = 'Stick'\n",
    "    print(\"NEW DATA\" + str(new_data.shape))\n",
    "    linc_data = pd.read_csv('../data/final_data/02_23_lincdata.csv').drop(columns='Unnamed: 0')\n",
    "    print(\"LINC DATA\" + str(linc_data.shape))\n",
    "    weld_data = pd.read_csv('../data/final_data/02_23_welddata.csv').drop(columns='Unnamed: 0')\n",
    "    print(\"CEWELD DATA\" + str(weld_data.shape))\n",
    "    cit_data = pd.read_csv('../data/cit_data/200124_cit_data.csv').drop(columns='Unnamed: 0')\n",
    "    print(\"CIT DATA\" + str(cit_data.shape))\n",
    "    \n",
    "    take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n",
    "    new_data['UTS'] = new_data['UTS'].combine(new_data['UTS(Kg/mm2)'], take_smaller)\n",
    "    new_data = new_data.drop(columns={'UTS(Kg/mm2)','Elong %'})\n",
    "    \n",
    "    \n",
    "    #line up datasets and merge them\n",
    "    new_data.columns = ['Diffusible Hydrogen', 'Moisture', 'Yield strength', 'Tensile', 'Hardness',\n",
    "           'Ferrite (Fn)', 'Hardness_Scale', 'V', 'C', 'Cr', 'Mn', 'Mo', 'Ni',\n",
    "           'P ', 'S ', 'Si', 'Cb', 'Cu', 'Category', 'Elongation']\n",
    "\n",
    "    linc_data.columns = ['As', 'C', 'Charpy', 'Cr', 'Cu', 'Diffusible Hydrogen', 'Elongation',\n",
    "           'Lateral', 'Mn', 'Mn + Ni + Cr + Mo + V', 'Mo', 'N', 'Nb', 'Ni',\n",
    "           'Ni+Mn', 'P', 'P S', 'S', 'S Ni', 'SN', 'Si', 'Si P', 'Sn', 'Tensile',\n",
    "           'V', 'Yield strength', 'aws', 'conformances', 'ind', 'key features',\n",
    "           'requirements', 'typic_results', 'typical applications', 'Category',\n",
    "           'name', 'url']\n",
    "\n",
    "    new_data = new_data.append(linc_data, ignore_index=True, sort=False)\n",
    "    new_data = new_data.append(weld_data, ignore_index=True, sort=False)\n",
    "    new_data = new_data.append(cit_data, ignore_index=True, sort=False)\n",
    "    \n",
    "    \n",
    "    #Merging Stick Columns\n",
    "    sticks = ['7018.0', '  6013 (REST)', '  LOTHERME', '  LOW ALLOY(SPL)', '  ST. STEELS', 'stainless-high-alloy', 'SMAW Stick Electrodes', 'stick-electrodes', '  6013 (NORMA-V)']\n",
    "\n",
    "    for s in sticks:\n",
    "        new_data['Category'] = new_data['Category'].replace(s,'Stick')\n",
    "    \n",
    "    #Identifying Stick and non-Stick\n",
    "    uns = new_data['Category'].unique()[1:]\n",
    "    for u in uns:\n",
    "        new_data['Category'] = new_data['Category'].replace(u,\"Others\")\n",
    "        new_data['Category'].unique()\n",
    "    uns = new_data['Category'].unique()\n",
    "\n",
    "    i = 0\n",
    "    for u in uns:\n",
    "        new_data['Category'] = new_data['Category'].replace(u,1-i)\n",
    "        i = i+1\n",
    "    \n",
    "    #1 means stick, 0 means other\n",
    "    new_data = new_data.drop(columns={'ind',\n",
    " 'Reduction of area',\n",
    " 'Ultimate tensile strength',\n",
    " 'Ferrite with carbide aggregate',\n",
    " 'Manual metal arc_Heat input',\n",
    " 'Manual metal arc_Interpass temperature',\n",
    " 'Submerged arc_Heat input',\n",
    " 'Submerged arc_Interpass temperature',\n",
    " 'extr'})\n",
    "    new_data = new_data.dropna(axis=1, thresh=100)\n",
    "    \n",
    "    \n",
    "    return new_data\n",
    "\n",
    "#If true it will only return stick dataset\n",
    "def get_ml_data(stick):\n",
    "    #Get merged dataset\n",
    "    df = get_merged_data()\n",
    "    \n",
    "    \n",
    "    #Get training dataset\n",
    "    df = numerify_df(df).astype(float)\n",
    "    columns = list(df.columns)\n",
    "    df = df.to_numpy()\n",
    "    \n",
    "    #Getting rid of non-sticks\n",
    "    df[df==0] = np.nan\n",
    "    if stick:\n",
    "        df = df[pd.notnull(df[:,columns.index(\"Category\")])]\n",
    "    \n",
    "    tmp = pd.DataFrame(df, columns = columns)\n",
    "    elems = get_elements(tmp).drop(columns={'A5', 'Rm'})\n",
    "    elem_cols = elems.columns\n",
    "    elems = numerify_df(elems).astype(float).to_numpy()\n",
    "    elems[elems==0] = np.nan\n",
    "    \n",
    "    \n",
    "        \n",
    "    return df, elems, elem_cols, columns\n",
    "\n",
    "#Getting all of the columns of parameters to predict\n",
    "def get_pred_cols():\n",
    "    pred_cs = ['Rm', 'A5']\n",
    "    for c in columns:\n",
    "        if len(c)>2:\n",
    "            pred_cs.append(c)\n",
    "    return pred_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods for pre-examining data\n",
    "\n",
    "def get_model_err(df,prop, model):\n",
    "    tmp = np.concatenate([elems, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    #tmp[tmp==0] = np.nan\n",
    "    #tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    print(y)\n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "    lin_reg = model\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    pred = lin_reg.predict(X_test)\n",
    "    err = sqrt(mean_squared_error(y_test, pred))\n",
    "    return err\n",
    "\n",
    "def get_model_residual(df,prop, model):\n",
    "    tmp = np.concatenate([elems, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    #tmp[tmp==0] = np.nan\n",
    "    #tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "    #Trying data transformation\n",
    "    X_train = X_train+0.0000000000000001\n",
    "    X_test = X_test+0.0000000000000001\n",
    "    X_train = np.power(X_train,-.2)\n",
    "    X_test = np.power(X_test,-.2)\n",
    "    lin_reg = ResidualsPlot(model)\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    lin_reg.score(X_test, y_test)\n",
    "    return lin_reg\n",
    "\n",
    "def try_model(model):\n",
    "    a = []\n",
    "    for c in get_pred_cols():\n",
    "        err = get_model_err(df, c,model)\n",
    "        a.append(err)\n",
    "    i = 0\n",
    "    zers = []\n",
    "    for c in a:\n",
    "        if c==0:\n",
    "            zers.append(get_pred_cols()[i])\n",
    "        print(get_pred_cols()[i] +\" \"+str(c))\n",
    "        i+=1\n",
    "    return zers\n",
    "        \n",
    "def get_res_plots(model):\n",
    "    a = []\n",
    "    for c in get_pred_cols():\n",
    "        err = get_model_residual(df, c,model)\n",
    "        print(columns[i])\n",
    "        err.show()\n",
    "        a.append(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW DATA(1509, 22)\n",
      "LINC DATA(944, 36)\n",
      "CEWELD DATA(678, 51)\n",
      "CIT DATA(1650, 75)\n"
     ]
    }
   ],
   "source": [
    "df, elems, elem_cols, columns = get_ml_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rm', 'A5', 'Diffusible Hydrogen', 'Moisture', 'Yield strength', 'Tensile', 'Ferrite (Fn)', 'Category', 'Elongation', 'Charpy', 'DIN_W', 'HT_Temp', 'IE-20', 'IE-40', 'IE-60', 'Redry_Time', 'Rp0']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72cb3589512448b9711ad613e7f828f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandadata = pd.DataFrame(df, columns= columns)\n",
    "print(get_pred_cols())\n",
    "qgrid.show_grid(pandadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0. ... 430. 500. 280.]\n",
      "[ 0.  0.  0. ...  0. 10.  0.]\n",
      "[0. 5. 5. ... 0. 0. 0.]\n",
      "[0.  0.3 0.3 ... 0.  0.  0. ]\n",
      "[  0. 200. 200. ...   0.   0.   0.]\n",
      "[  0. 550. 550. ...   0.   0.   0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[ 0. 11. 11. ...  0.  0.  0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.     0.     0.     ... 0.     0.     2.1025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasann/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 1. 1. 2.]\n",
      "[  0.   0.   0. ...   0. 350. 120.]\n",
      "Rm 78.33190310752646\n",
      "A5 3.860297078497216\n",
      "Diffusible Hydrogen 0.5262908604177822\n",
      "Moisture 0.016193296028648656\n",
      "Yield strength 82.05978605977151\n",
      "Tensile 100.8842089545413\n",
      "Ferrite (Fn) 0.7932983361704499\n",
      "Category 0.0\n",
      "Elongation 4.3379933782990605\n",
      "Charpy 21.119753363538404\n",
      "DIN_W 0.13722751221086144\n",
      "HT_Temp 27.01367498811734\n",
      "IE-20 23.47501284795281\n",
      "IE-40 18.151114416075245\n",
      "IE-60 6.227109973687223\n",
      "Redry_Time 0.1526048846801058\n",
      "Rp0 8490.092398910017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Category']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_model(RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very computationally expensive\n",
    "#t = try_model(svm.SVR(kernel = 'linear', C=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0. ... 430. 500. 280.]\n",
      "[19:24:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[ 0.  0.  0. ...  0. 10.  0.]\n",
      "[19:24:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0. 5. 5. ... 0. 0. 0.]\n",
      "[19:24:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0.  0.3 0.3 ... 0.  0.  0. ]\n",
      "[19:24:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[  0. 200. 200. ...   0.   0.   0.]\n",
      "[19:24:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[  0. 550. 550. ...   0.   0.   0.]\n",
      "[19:24:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[19:24:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[19:24:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[ 0. 11. 11. ...  0.  0.  0.]\n",
      "[19:24:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[19:24:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0.     0.     0.     ... 0.     0.     2.1025]\n",
      "[19:24:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[19:24:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[19:24:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[19:24:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[19:24:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0. 0. 0. ... 1. 1. 2.]\n",
      "[19:24:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[  0.   0.   0. ...   0. 350. 120.]\n",
      "[19:24:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Rm 95.73609690519778\n",
      "A5 4.37212220449488\n",
      "Diffusible Hydrogen 0.8003631191300946\n",
      "Moisture 0.018831300843914493\n",
      "Yield strength 86.11930324346349\n",
      "Tensile 109.30103920571925\n",
      "Ferrite (Fn) 1.0344317773128888\n",
      "Category 1.33514404296875e-05\n",
      "Elongation 4.875975332747353\n",
      "Charpy 20.74202433437285\n",
      "DIN_W 0.17847206012738967\n",
      "HT_Temp 58.1617424222538\n",
      "IE-20 41.87495923365039\n",
      "IE-40 23.032069096834043\n",
      "IE-60 19.11436247674536\n",
      "Redry_Time 0.2068954129910085\n",
      "Rp0 8492.449889209438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_model(XGBRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-66333039574b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstantKernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRBF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianProcessRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_model_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Charpy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-036b0a6d2993>\u001b[0m in \u001b[0;36mget_model_err\u001b[0;34m(df, prop, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlin_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mlin_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlin_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    219\u001b[0m             optima = [(self._constrained_optimization(obj_func,\n\u001b[1;32m    220\u001b[0m                                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                                                       self.kernel_.bounds))]\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;31m# Additional runs are performed from log-uniform chosen initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fmin_l_bfgs_b\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mtheta_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvergence_dict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m                 \u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvergence_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                 warnings.warn(\"fmin_l_bfgs_b terminated abnormally with the \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     lml, grad = self.log_marginal_likelihood(\n\u001b[0;32m--> 213\u001b[0;31m                         theta, eval_gradient=True)\n\u001b[0m\u001b[1;32m    214\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag_indices_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Line 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \"\"\"\n\u001b[1;32m     90\u001b[0m     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n\u001b[0;32m---> 91\u001b[0;31m                          check_finite=check_finite)\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0moverwrite_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverwrite_a\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_datacopied\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mpotrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'potrf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpotrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#trying out Gaussian Processes\n",
    "import sklearn.gaussian_process as gp\n",
    "kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\n",
    "model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=True)\n",
    "get_model_err(df, \"Charpy\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization code 2\n",
    "\n",
    "models = {\n",
    "    'logistic_regression': LogisticRegression,\n",
    "    'rf': RandomForestRegressor,\n",
    "    'knn': KNeighborsRegressor, 'svr': SVR,\n",
    "    'xgb': XGBRegressor\n",
    "}\n",
    "\n",
    "\n",
    "def search_space(model):\n",
    "\n",
    "    model = model.lower()\n",
    "    space = {}\n",
    "\n",
    "    if model == 'knn':\n",
    "        space = {'n_neighbors': hp.choice('n_neighbors', range(1, 100)),\n",
    "\n",
    "\n",
    "                 }\n",
    "\n",
    "    elif model == 'xgb':\n",
    "        space = {'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "    'silent':True,\n",
    "                 }\n",
    "\n",
    "    elif model == 'svr':\n",
    "        space = {\n",
    "            'C': hp.uniform('C', 0, 20),\n",
    "            'kernel': hp.choice('kernel', ['linear', 'sigmoid', 'poly', 'rbf']),\n",
    "            'gamma': hp.uniform('gamma', 0, 20),\n",
    "        }\n",
    "\n",
    "    \n",
    "    elif model == 'rf':\n",
    "        space = {'max_depth': hp.choice('max_depth', range(1, 20)),\n",
    "                 'max_features': hp.choice('max_features', range(1, 10)),\n",
    "                 'n_estimators': hp.choice('n_estimators', range(10, 50)),\n",
    "                 'criterion': hp.choice('criterion', ['mse', 'mae']),\n",
    "                 }\n",
    "        \n",
    "    elif model == 'cat':\n",
    "        space = {'learning_rate':     hp.choice('learning_rate',     np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':         hp.choice('max_depth',         np.arange(5, 16, 1, dtype=int)),\n",
    "    'colsample_bylevel': hp.choice('colsample_bylevel', np.arange(0.3, 0.8, 0.1)),\n",
    "    'n_estimators':      100,\n",
    "    'eval_metric':       'RMSE',\n",
    "    'silent':True\n",
    "                 }\n",
    "    elif model == 'lgb':\n",
    "        space = {'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "                 'silent':True\n",
    "                 }\n",
    "        \n",
    "    elif model == 'logistic_regression':\n",
    "        space = {\n",
    "            'warm_start': hp.choice('warm_start', [True, False]),\n",
    "            'fit_intercept': hp.choice('fit_intercept', [True, False]),\n",
    "            'tol': hp.uniform('tol', 0.00001, 0.0001),\n",
    "            'C': hp.uniform('C', 0.05, 3),\n",
    "            'solver': hp.choice('solver', ['newton-cg', 'lbfgs', 'liblinear']),\n",
    "            'max_iter': hp.choice('max_iter', range(100, 1000)),\n",
    "            'multi_class': 'auto',\n",
    "            'class_weight': 'balanced'\n",
    "        }\n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import space_eval\n",
    "kf = KFold(n_splits=5, random_state=42)\n",
    "curmodel = XGBRegressor\n",
    "dataset = 1\n",
    "curvar = \"\"\n",
    "def get_data(prop):\n",
    "    tmp = np.concatenate([elems, df[:,columns.index(prop)].reshape(len(df),1)], axis=1)\n",
    "    tmp = np.nan_to_num(tmp)\n",
    "    \n",
    "    #tmp[tmp==0] = np.nan\n",
    "    #tmp = tmp[pd.notnull(tmp[:,-1])]\n",
    "    y = tmp[:,-1]\n",
    "    \n",
    "    X = np.nan_to_num(tmp)\n",
    "    X = X[:,:-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.333, random_state=52, shuffle=True)\n",
    "    return x_val, x_test, x_train, y_val, y_test, y_train\n",
    "\n",
    "def run_opt(prop, space):\n",
    "    global curvar\n",
    "    global curmodel\n",
    "    print(prop)\n",
    "    curmodel = models[space]\n",
    "    curvar = prop\n",
    "    trials = Trials()\n",
    "    \n",
    "    #TODO change max_evals to 100\n",
    "    best = fmin(fn=objective,\n",
    "                space=search_space(space),\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=1,\n",
    "                trials=trials)\n",
    "    \n",
    "    return trials.best_trial['result']['loss'], trials.best_trial['result']['sco'], best\n",
    "\n",
    "def get_opt_model(prop, space):\n",
    "    global curvar\n",
    "    global curmodel\n",
    "    #TODO Change max evals to 100\n",
    "    curmodel = models[space]\n",
    "    curvar = prop\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=objective,\n",
    "                space=search_space(space),\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=1,\n",
    "                trials=trials,\n",
    "               return_argmin=False)\n",
    "    \n",
    "    model = get_model(best)\n",
    "    \n",
    "    return model, trials.best_trial['result']['loss'], trials.best_trial['result']['sco'], best\n",
    "\n",
    "\n",
    "def get_model(space):\n",
    "    global curvar\n",
    "    global curmodel\n",
    "    #print(space)\n",
    "    if(curmodel==XGBRegressor):\n",
    "        clf = curmodel(\n",
    "                               **space, objective = 'reg:squarederror'\n",
    "                                )\n",
    "    else:\n",
    "        clf = curmodel(\n",
    "                               **space\n",
    "                                )\n",
    "\n",
    "    \n",
    "    x_val, x_test, x_train, y_val, y_test, y_train = get_data(curvar)\n",
    "    \n",
    "    eval_set  = [( x_train, y_train), ( x_val, y_val)]\n",
    "\n",
    "    if(curmodel==XGBRegressor):\n",
    "        clf.fit(x_train, y_train,\n",
    "                eval_set=eval_set, eval_metric=\"rmse\",\n",
    "                early_stopping_rounds=10,verbose=False,)\n",
    "    else:\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "    pred = clf.predict(x_test)\n",
    "    mse_scr = -cross_val_score(clf, x_train, y_train, cv=kf, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "    #print (\"SCORE:\", np.sqrt(mean_squared_error(y_test, pred)))\n",
    "    #change the metric if you like|\n",
    "    pred = clf.predict(x_test)\n",
    "    score = np.sqrt(mean_squared_error(y_test, pred))\n",
    "    return clf\n",
    "\n",
    "def objective(space):\n",
    "    global curvar\n",
    "    global curmodel\n",
    "    #print(space)\n",
    "    if(curmodel==XGBRegressor):\n",
    "        clf = curmodel(\n",
    "                               **space, objective = 'reg:squarederror'\n",
    "                                )\n",
    "    else:\n",
    "        clf = curmodel(\n",
    "                               **space\n",
    "                                )\n",
    "\n",
    "    x_val, x_test, x_train, y_val, y_test, y_train = get_data(curvar)\n",
    "    \n",
    "    eval_set  = [( x_train, y_train), ( x_val, y_val)]\n",
    "\n",
    "    print(clf)\n",
    "    if(curmodel==XGBRegressor):\n",
    "        clf.fit(x_train, y_train,\n",
    "                eval_set=eval_set, eval_metric=\"rmse\",\n",
    "                early_stopping_rounds=10,verbose=False,)\n",
    "    else:\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "    pred = clf.predict(x_test)\n",
    "    mse_scr = -cross_val_score(clf, x_train, y_train, cv=kf, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "    #print (\"SCORE:\", np.sqrt(mean_squared_error(y_test, pred)))\n",
    "    #change the metric if you like\n",
    "    pred = clf.predict(x_test)\n",
    "    score = np.sqrt(mean_squared_error(y_test, pred))\n",
    "    return {'loss':np.sqrt(mse_scr), 'status': STATUS_OK, 'sco':score }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for getting benchmarks using hyperopt code 2\n",
    "def get_benchmarks():\n",
    "    d = pd.DataFrame()\n",
    "    a = {}\n",
    "    a['data'] = dataset\n",
    "    mods = []\n",
    "    for m in models.keys():\n",
    "        print(m)\n",
    "        a['model'] = m\n",
    "        for c in get_pred_cols():\n",
    "            if c is not 'Category':\n",
    "                print(c)\n",
    "                a['column'] = c\n",
    "                mod, v, t, p = get_opt_model(c, m)\n",
    "                a['validation'], a['test'], a['params'] = run_opt(c, m)\n",
    "                d = d.append(a, ignore_index=True, sort=False)\n",
    "                mods.append(mod)\n",
    "    return d, mods\n",
    "\n",
    "def get_models(prop):\n",
    "    d = []\n",
    "    for c in get_pred_cols():\n",
    "        if c is not 'Category':\n",
    "            d.append(get_opt_model(c, prop))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=19.25734549517949, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "    gamma=16.349979347749525, kernel='sigmoid', max_iter=-1, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.12s/trial, best loss: 149.06805397687774]\n",
      "SVR(C=12.801313708145468, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "    gamma=18.497038972106893, kernel='linear', max_iter=-1, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "get_models('svr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n",
      "Rm\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.72trial/s, best loss: 1.33514404296875e-05]\n",
      "A5\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.30trial/s, best loss: 1.33514404296875e-05]\n",
      "Diffusible Hydrogen\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.43trial/s, best loss: 1.33514404296875e-05]\n",
      "Moisture\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.98trial/s, best loss: 1.33514404296875e-05]\n",
      "Yield strength\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.39trial/s, best loss: 1.33514404296875e-05]\n",
      "Tensile\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.45trial/s, best loss: 1.33514404296875e-05]\n",
      "Hardness\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.77trial/s, best loss: 1.33514404296875e-05]\n",
      "Ferrite (Fn)\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.46trial/s, best loss: 1.33514404296875e-05]\n",
      "Category\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.46trial/s, best loss: 1.33514404296875e-05]\n",
      "Elongation\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.05trial/s, best loss: 1.33514404296875e-05]\n",
      "Charpy\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.36trial/s, best loss: 1.33514404296875e-05]\n",
      "DIN_W\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.44trial/s, best loss: 1.33514404296875e-05]\n",
      "HT_Temp\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.92trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-20\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.35trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-40\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.40trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-60\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.81trial/s, best loss: 1.33514404296875e-05]\n",
      "Redry_Time\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.27trial/s, best loss: 1.33514404296875e-05]\n",
      "Rp0\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.45trial/s, best loss: 1.33514404296875e-05]\n",
      "rf\n",
      "Rm\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.50trial/s, best loss: 0.00394517183303833]\n",
      "A5\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.38trial/s, best loss: 0.002876877784729004]\n",
      "Diffusible Hydrogen\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.85trial/s, best loss: 0.004869699478149414]\n",
      "Moisture\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.44trial/s, best loss: 0.004869699478149414]\n",
      "Yield strength\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.64trial/s, best loss: 0.023617267608642578]\n",
      "Tensile\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.03trial/s, best loss: 0.003196239471435547]\n",
      "Hardness\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.12trial/s, best loss: 0.002876877784729004]\n",
      "Ferrite (Fn)\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.48trial/s, best loss: 0.003551006317138672]\n",
      "Category\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.84trial/s, best loss: 0.00394517183303833]\n",
      "Elongation\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.13trial/s, best loss: 0.003196239471435547]\n",
      "Charpy\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.54trial/s, best loss: 0.002876877784729004]\n",
      "DIN_W\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.77trial/s, best loss: 0.004869699478149414]\n",
      "HT_Temp\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.37trial/s, best loss: 0.00394517183303833]\n",
      "IE-20\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.51trial/s, best loss: 0.003551006317138672]\n",
      "IE-40\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.85trial/s, best loss: 0.006677985191345215]\n",
      "IE-60\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.96trial/s, best loss: 0.002876877784729004]\n",
      "Redry_Time\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.51trial/s, best loss: 0.004383087158203125]\n",
      "Rp0\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.03trial/s, best loss: 0.003196239471435547]\n",
      "knn\n",
      "Rm\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.64trial/s, best loss: 1.33514404296875e-05]\n",
      "A5\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.77trial/s, best loss: 1.33514404296875e-05]\n",
      "Diffusible Hydrogen\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.74trial/s, best loss: 1.33514404296875e-05]\n",
      "Moisture\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.80trial/s, best loss: 1.33514404296875e-05]\n",
      "Yield strength\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.70trial/s, best loss: 1.33514404296875e-05]\n",
      "Tensile\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.81trial/s, best loss: 1.33514404296875e-05]\n",
      "Hardness\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.82trial/s, best loss: 1.33514404296875e-05]\n",
      "Ferrite (Fn)\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.84trial/s, best loss: 1.33514404296875e-05]\n",
      "Category\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.82trial/s, best loss: 1.33514404296875e-05]\n",
      "Elongation\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.73trial/s, best loss: 1.33514404296875e-05]\n",
      "Charpy\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.72trial/s, best loss: 1.33514404296875e-05]\n",
      "DIN_W\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.65trial/s, best loss: 1.33514404296875e-05]\n",
      "HT_Temp\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.70trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-20\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.61trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-40\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.59trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-60\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.52trial/s, best loss: 1.33514404296875e-05]\n",
      "Redry_Time\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.66trial/s, best loss: 1.33514404296875e-05]\n",
      "Rp0\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.55trial/s, best loss: 1.33514404296875e-05]\n",
      "svr\n",
      "Rm\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.82trial/s, best loss: 1.33514404296875e-05]\n",
      "A5\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.77trial/s, best loss: 1.33514404296875e-05]\n",
      "Diffusible Hydrogen\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.87trial/s, best loss: 1.33514404296875e-05]\n",
      "Moisture\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.83trial/s, best loss: 1.33514404296875e-05]\n",
      "Yield strength\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.83trial/s, best loss: 1.33514404296875e-05]\n",
      "Tensile\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.75trial/s, best loss: 1.33514404296875e-05]\n",
      "Hardness\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.81trial/s, best loss: 1.33514404296875e-05]\n",
      "Ferrite (Fn)\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.73trial/s, best loss: 1.33514404296875e-05]\n",
      "Category\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.71trial/s, best loss: 1.33514404296875e-05]\n",
      "Elongation\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.76trial/s, best loss: 1.33514404296875e-05]\n",
      "Charpy\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.77trial/s, best loss: 1.33514404296875e-05]\n",
      "DIN_W\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.70trial/s, best loss: 1.33514404296875e-05]\n",
      "HT_Temp\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.77trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-20\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.81trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-40\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.87trial/s, best loss: 1.33514404296875e-05]\n",
      "IE-60\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.92trial/s, best loss: 1.33514404296875e-05]\n",
      "Redry_Time\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.84trial/s, best loss: 1.33514404296875e-05]\n",
      "Rp0\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.84trial/s, best loss: 1.33514404296875e-05]\n",
      "xgb\n",
      "Rm\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.50trial/s, best loss: -0.0]                \n",
      "A5\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.34trial/s, best loss: -0.0]\n",
      "Diffusible Hydrogen\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.29trial/s, best loss: -0.0]\n",
      "Moisture\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.21trial/s, best loss: -0.0]                \n",
      "Yield strength\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.11trial/s, best loss: -0.0]                 \n",
      "Tensile\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.50trial/s, best loss: -0.0]                \n",
      "Hardness\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.34trial/s, best loss: -0.0]                \n",
      "Ferrite (Fn)\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.28trial/s, best loss: -0.0]                 \n",
      "Category\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.15trial/s, best loss: -0.0]\n",
      "Elongation\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.76trial/s, best loss: -0.0]                \n",
      "Charpy\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.86trial/s, best loss: -0.0]                 \n",
      "DIN_W\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.01trial/s, best loss: -0.0]                \n",
      "HT_Temp\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.69trial/s, best loss: -0.0]                \n",
      "IE-20\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.75trial/s, best loss: -0.0]               \n",
      "IE-40\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.81trial/s, best loss: -0.0]\n",
      "IE-60\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.70trial/s, best loss: -0.0]                \n",
      "Redry_Time\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.32trial/s, best loss: -0.0]                 \n",
      "Rp0\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.49trial/s, best loss: -0.0]\n"
     ]
    }
   ],
   "source": [
    "d = get_benchmarks()\n",
    "d.to_csv('../benchmarks/benchmark_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "973px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
